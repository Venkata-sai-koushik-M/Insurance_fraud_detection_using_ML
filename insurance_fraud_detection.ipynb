{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insurance Fraud Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Required Libraries\n",
    "Import the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of dataset:\n",
      "  PolicyHolder  ClaimAmount ClaimType  Fraudulent\n",
      "0     John Doe         5000    Health           0\n",
      "1   Jane Smith        12000      Auto           1\n",
      "2  Alice Brown         7000      Home           0\n",
      "3    Bob White        15000      Auto           1\n",
      "4    Eve Black         9000    Health           0\n",
      "\n",
      "Missing Values in Dataset:\n",
      "PolicyHolder    0\n",
      "ClaimAmount     0\n",
      "ClaimType       0\n",
      "Fraudulent      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"First 5 rows of dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Dataset:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Fill missing values (if any)\n",
    "data = data.ffill()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "data['PolicyHolder'] = le.fit_transform(data['PolicyHolder'])\n",
    "data['ClaimType'] = le.fit_transform(data['ClaimType'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "Fraudulent\n",
      "0    5\n",
      "1    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.drop(columns=['Fraudulent'])\n",
    "y = data['Fraudulent']\n",
    "\n",
    "# Check class distribution (to see if it's imbalanced)\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE only if data is imbalanced\n",
    "if y_train.value_counts().min() < 0.3 * y_train.value_counts().max():\n",
    "    print(\"\\nApplying SMOTE to balance data...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: RandomForestClassifier\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "Accuracy: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.75      0.50      0.33         2\n",
      "weighted avg       0.75      0.50      0.33         2\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [1 0]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.75      0.50      0.33         2\n",
      "weighted avg       0.75      0.50      0.33         2\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [1 0]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Model training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=1))  # Fix precision warning\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# List of models\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model in models:\n",
    "    train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\n✅ Model training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Conclusion\n",
    "This notebook successfully trains models to detect fraudulent claims."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
